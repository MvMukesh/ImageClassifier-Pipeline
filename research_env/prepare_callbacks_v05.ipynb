{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks enhances training, monitoring progress, and ensuring best model is saved. \n",
    "\n",
    "Some common use cases for callbacks:\n",
    "\n",
    "1. **Model Checkpointing:**\n",
    "   - **Purpose:** Save the model's weights during training.\n",
    "   - **Advantage:** Ensures that the best model (based on a chosen metric) is saved, allowing you to resume training or use the model for inference later.\n",
    "   - **Example Callback:** `ModelCheckpoint`\n",
    "\n",
    "2. **Early Stopping:**\n",
    "   - **Purpose:** Halt training if a certain condition (e.g., no improvement in validation loss) is met.\n",
    "   - **Advantage:** Prevents overfitting and saves training time.\n",
    "   - **Example Callback:** `EarlyStopping`\n",
    "\n",
    "3. **Learning Rate Scheduling:**\n",
    "   - **Purpose:** Adjust the learning rate during training to optimize convergence.\n",
    "   - **Advantage:** Helps fine-tune the model by dynamically adapting the learning rate.\n",
    "   - **Example Callback:** Custom callback or `ReduceLROnPlateau`\n",
    "\n",
    "4. **TensorBoard Integration:**\n",
    "   - **Purpose:** Log training metrics for visualization in TensorBoard.\n",
    "   - **Advantage:** Provides interactive visualizations of metrics like loss and accuracy.\n",
    "   - **Example Callback:** `TensorBoard`\n",
    "\n",
    "5. **Custom Logging and Monitoring:**\n",
    "   - **Purpose:** Log custom metrics or information during training.\n",
    "   - **Advantage:** Allows you to track specific aspects of the training process not covered by default metrics.\n",
    "   - **Example Callback:** Custom callback for logging\n",
    "\n",
    "6. **Data Augmentation Monitoring:**\n",
    "   - **Purpose:** Monitor the effects of data augmentation on model performance.\n",
    "   - **Advantage:** Provides insights into how augmentation impacts the training process.\n",
    "   - **Example Callback:** Custom callback for visualizing augmented images\n",
    "\n",
    "7. **Gradient Clipping:**\n",
    "   - **Purpose:** Limit the magnitude of gradients during training.\n",
    "   - **Advantage:** Helps prevent exploding gradients and stabilizes training.\n",
    "   - **Example Callback:** Custom callback for gradient clipping\n",
    "\n",
    "These callbacks collectively contribute to efficient training, model selection, and performance monitoring in a deep learning image classification pipeline. They enhance the adaptability of the pipeline to various scenarios and improve the overall training experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of key points about using callbacks\n",
    "\n",
    "\n",
    "| **Callback**               | **Advantages**                                           | **Disadvantages**                                       | **When to Use**                                                                                                                                                                                                                                                                                             | **When Not to Use**                                                                                                                                                                                                |\n",
    "|------------------------|---------------------------------------------------------|---------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Model Checkpoint      | - Saves the best model weights.                        | - Adds storage overhead for saving multiple checkpoints. | - Use when you want to save the best model during training for later use in inference or further training.                                                                                                                                     | - When storage constraints are severe, and saving multiple checkpoints is not feasible.                                                                                                                           |\n",
    "| Early Stopping           | - Prevents overfitting by stopping training early.     | - May stop training too early, missing potential gains.  | - Use when you want to automatically stop training when a specified metric (e.g., validation loss) stops improving, preventing overfitting.                                                                                               | - When you want to run the training process for a fixed number of epochs, ignoring early stopping criteria.                                                                                                      |\n",
    "| Learning Rate Schedule | - Dynamically adjusts learning rate during training.   | - Choosing an inappropriate schedule can harm convergence. | - Use when you want to adaptively adjust the learning rate to optimize convergence, especially in scenarios with varying gradients or non-uniform data.                                                                                    | - When learning rate tuning is unnecessary or the learning rate is fixed throughout training.                                                                                                                   |\n",
    "| TensorBoard            | - Provides interactive visualizations of training metrics. | - Adds some computational overhead for logging.          | - Use when you want to monitor and visualize metrics (e.g., loss, accuracy) in real-time using TensorBoard.                                                                                                                                   | - When visualization of training metrics is not a priority, or computational resources are limited.                                                                                                            |\n",
    "| Custom Logging         | - Allows logging of custom metrics or information.       | - Requires additional coding for custom logging logic.  | - Use when you need to track specific information or metrics not covered by default callbacks.                                                                                                                                                 | - In standard cases where default logging is sufficient, and there is no need for additional custom logging.                                                                                                  |\n",
    "| Data Augmentation Monitoring | - Visualizes the effects of data augmentation.     | - May increase the complexity of monitoring.            | - Use when you want insights into how data augmentation impacts model training, helping to assess its effectiveness.                                                                                                                         | - When data augmentation has minimal impact on model performance or monitoring its effects is not a priority.                                                                                                |\n",
    "| Gradient Clipping      | - Stabilizes training by limiting gradient magnitudes.  | - May affect convergence if clipping threshold is too low. | - Use when dealing with exploding gradient issues during training, preventing instability.                                                                                                                                                | - In cases where gradients are well-behaved and clipping is unnecessary.                                                                                                                                              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/manralai/Drive D/ImageClassifier-Pipeline/research_env'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/manralai/Drive D/ImageClassifier-Pipeline\n"
     ]
    }
   ],
   "source": [
    "## to root\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuraion Manager Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from imageClassifier.constants import *\n",
    "from imageClassifier.utils import read_yaml, create_directories\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,config_filepath=CONFIG_FILE_PATH,params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([Path(model_ckpt_dir),\n",
    "                            Path(config.tensorboard_root_log_dir)])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(root_dir=Path(config.root_dir),\n",
    "                                                         tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
    "                                                         checkpoint_model_filepath=Path(config.checkpoint_model_filepath))\n",
    "        return prepare_callback_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Componens Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n",
    "import urllib.request as request\n",
    "\n",
    "\n",
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "    @property\n",
    "    def _create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(self.config.tensorboard_root_log_dir,f\"tb_logs_at_{timestamp}\",)\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
    "\n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(filepath=str(self.config.checkpoint_model_filepath),save_best_only=True)\n",
    "\n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [self._create_tb_callbacks,self._create_ckpt_callbacks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above Warning\n",
    "\n",
    "In summary, above output suggests that TensorFlow is running on the CPU due to the absence of CUDA drivers for the GPU. Additionally, it provides information about optimization and warns about the unavailability of TensorRT, which is relevant for GPU-based inference optimizations on NVIDIA GPUs. If you intend to use the GPU, ensure that CUDA and cuDNN are properly installed and configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 13:08:38,217: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-01-06 13:08:38,227: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-01-06 13:08:38,230: INFO: common: Created directory at: artifacts]\n",
      "[2024-01-06 13:08:38,234: INFO: common: Created directory at: artifacts/prepare_callbacks/checkpoint_dir]\n",
      "[2024-01-06 13:08:38,238: INFO: common: Created directory at: artifacts/prepare_callbacks/tensorboard_log_dir]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_imgClfPipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
